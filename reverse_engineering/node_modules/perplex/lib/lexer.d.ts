import LexerState from './lexer-state';
import Token, { EOF } from './token';
import TokenTypes from './token-types';
/**
 * @typedef {{
 *   line: number,
 *   column: number,
 * }} Position
 */
/**
 * Lexes a source-string into tokens.
 *
 * @example
 * const lex = perplex('...')
 *   .token('ID', /my-id-regex/)
 *   .token('(', /\(/)
 *   .token(')', /\)/)
 *   .token('WS', /\s+/, true) // true means 'skip'
 *
 * while ((let t = lex.next()).type != 'EOF') {
 *   console.log(t)
 * }
 * // alternatively:
 * console.log(lex.toArray())
 */
declare class Lexer<T> {
    private _state;
    private _tokenTypes;
    /**
     * Creates a new Lexer instance
     * @param {string} [source = ''] The source string to operate on.
     */
    constructor(source?: string);
    /**
     * Gets the current lexer position
     * @return {number} Returns the position
     */
    /**
     * Sets the current lexer position
     * @param {number} i The position to move to
     */
    position: number;
    /**
     * Gets the source the lexer is operating on
     * @return {string} Returns the source
     */
    /**
     * Sets the source the lexer is operating on
     * @param {string} s The source to set
     */
    source: string;
    /**
     * Attaches this lexer to another lexer's state
     * @param {Lexer<T>} other The other lexer to attach to
     */
    attachTo(other: Lexer<T>): void;
    /**
     * Disables a token type
     * @param {T} type The token type to disable
     * @return {Lexer<T>}
     */
    disable(type: T): this;
    /**
     * Enables a token type
     * @param {T} type The token type to enalbe
     * @param {?boolean} [enabled=true] Whether to enable/disable the specified token type
     * @return {Lexer<T>}
     */
    enable(type: T, enabled?: boolean): this;
    /**
     * Like {@link next}, but throws an exception if the next token is
     * not of the required type.
     * @param {T} type The token type expected from {@link next}
     * @return {Token<T>} Returns the {@link Token} on success
     */
    expect(type: T): Token<T>;
    /**
     * Looks up whether a token is enabled.
     * @param tokenType The token type to look up
     * @return {boolean} Returns whether the token is enabled
     */
    isEnabled(tokenType: T): boolean;
    /**
     * Consumes and returns the next {@link Token} in the source string.
     * If there are no more tokens, it returns a {@link Token} of type `$EOF`
     * @return {Token<T>}
     */
    next(): Token<T>;
    /**
     * Returns the next {@link Token} in the source string, but does
     * not consume it.
     * If there are no more tokens, it returns a {@link Token} of type `$EOF`
     * @param {number} [position=`this.position`] The position at which to start reading
     * @return {Token<T>}
     */
    peek(position?: number): Token<T>;
    /**
     * Converts a string-index (relative to the source string) to a line and a column.
     * @param {number} i The index to compute
     * @return {Position}
     */
    strpos(i: number): {
        line: number;
        column: number;
    };
    /**
     * Converts the token stream to an array of Tokens
     * @return {Token<T>[]} The array of tokens (not including (EOF))
     */
    toArray(): Token<T>[];
    /**
     * Creates a new token type
     * @param {T} type The token type
     * @param {string|RegExp} pattern The pattern to match
     * @param {?boolean} skip Whether this type of token should be skipped
     * @return {Lexer<T>}
     */
    token(type: T, pattern: string | RegExp, skip?: boolean): this;
    /**
     * Creates a keyword
     * @param kwd The keyword to add as a token
     */
    keyword(kwd: T): this;
    /**
     * Creates an operator
     * @param op The operator to add as a token
     */
    operator(op: T): this;
}
export default Lexer;
export { EOF, Token, TokenTypes, LexerState };
