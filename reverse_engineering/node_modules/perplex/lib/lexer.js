"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
var lexer_state_1 = require("./lexer-state");
exports.LexerState = lexer_state_1.default;
var token_1 = require("./token");
exports.Token = token_1.default;
exports.EOF = token_1.EOF;
var token_types_1 = require("./token-types");
exports.TokenTypes = token_types_1.default;
/**
 * @typedef {{
 *   line: number,
 *   column: number,
 * }} Position
 */
/**
 * Lexes a source-string into tokens.
 *
 * @example
 * const lex = perplex('...')
 *   .token('ID', /my-id-regex/)
 *   .token('(', /\(/)
 *   .token(')', /\)/)
 *   .token('WS', /\s+/, true) // true means 'skip'
 *
 * while ((let t = lex.next()).type != 'EOF') {
 *   console.log(t)
 * }
 * // alternatively:
 * console.log(lex.toArray())
 */
var Lexer = (function () {
    /* tslint:enable */
    /**
     * Creates a new Lexer instance
     * @param {string} [source = ''] The source string to operate on.
     */
    function Lexer(source) {
        if (source === void 0) { source = ''; }
        this._state = new lexer_state_1.default(source);
        this._tokenTypes = new token_types_1.default();
    }
    Object.defineProperty(Lexer.prototype, "position", {
        //
        // Getters/Setters
        //
        /**
         * Gets the current lexer position
         * @return {number} Returns the position
         */
        get: function () {
            return this._state.position;
        },
        /**
         * Sets the current lexer position
         * @param {number} i The position to move to
         */
        set: function (i) {
            this._state.position = i;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(Lexer.prototype, "source", {
        /**
         * Gets the source the lexer is operating on
         * @return {string} Returns the source
         */
        get: function () {
            return this._state.source;
        },
        /**
         * Sets the source the lexer is operating on
         * @param {string} s The source to set
         */
        set: function (s) {
            this._state = new lexer_state_1.default(s);
        },
        enumerable: true,
        configurable: true
    });
    //
    // METHODS
    //
    /**
     * Attaches this lexer to another lexer's state
     * @param {Lexer<T>} other The other lexer to attach to
     */
    Lexer.prototype.attachTo = function (other) {
        this._state = other._state;
    };
    /**
     * Disables a token type
     * @param {T} type The token type to disable
     * @return {Lexer<T>}
     */
    Lexer.prototype.disable = function (type) {
        this._tokenTypes.disable(type);
        return this;
    };
    /**
     * Enables a token type
     * @param {T} type The token type to enalbe
     * @param {?boolean} [enabled=true] Whether to enable/disable the specified token type
     * @return {Lexer<T>}
     */
    Lexer.prototype.enable = function (type, enabled) {
        this._tokenTypes.enable(type, enabled);
        return this;
    };
    /**
     * Like {@link next}, but throws an exception if the next token is
     * not of the required type.
     * @param {T} type The token type expected from {@link next}
     * @return {Token<T>} Returns the {@link Token} on success
     */
    Lexer.prototype.expect = function (type) {
        var t = this.next();
        if (t.type != type) {
            var pos = t.strpos();
            throw new Error('Expected ' +
                type +
                (t ? ', got ' + t.type : '') +
                ' at ' +
                pos.start.line +
                ':' +
                pos.start.column);
        }
        return t;
    };
    /**
     * Looks up whether a token is enabled.
     * @param tokenType The token type to look up
     * @return {boolean} Returns whether the token is enabled
     */
    Lexer.prototype.isEnabled = function (tokenType) {
        return this._tokenTypes.isEnabled(tokenType);
    };
    /**
     * Consumes and returns the next {@link Token} in the source string.
     * If there are no more tokens, it returns a {@link Token} of type `$EOF`
     * @return {Token<T>}
     */
    Lexer.prototype.next = function () {
        try {
            var t = this.peek();
            this._state.position = t.end;
            return t;
        }
        catch (e) {
            this._state.position = e.end;
            throw e;
        }
    };
    /**
     * Returns the next {@link Token} in the source string, but does
     * not consume it.
     * If there are no more tokens, it returns a {@link Token} of type `$EOF`
     * @param {number} [position=`this.position`] The position at which to start reading
     * @return {Token<T>}
     */
    Lexer.prototype.peek = function (position) {
        var _this = this;
        if (position === void 0) { position = this._state.position; }
        var read = function (i) {
            if (i === void 0) { i = position; }
            if (i >= _this._state.source.length)
                return token_1.EOF(_this);
            var n = _this._tokenTypes.peek(_this._state.source, i);
            return n
                ? n.item.skip
                    ? read(i + n.result[0].length)
                    : new token_1.default(n.item.type, n.result[0], n.result.map(function (x) { return x; }), i, i + n.result[0].length, _this)
                : null;
        };
        var t = read();
        if (t)
            return t;
        // we did not find a match
        var unexpected = this._state.source.substring(position, position + 1);
        try {
            this.peek(position + 1);
        }
        catch (e) {
            unexpected += e.unexpected;
        }
        var _a = this.strpos(position), line = _a.line, column = _a.column;
        var e = new Error("Unexpected input: " + unexpected + " at (" + line + ":" + column + ")");
        e.unexpected = unexpected;
        e.end = position + unexpected.length;
        throw e;
    };
    /**
     * Converts a string-index (relative to the source string) to a line and a column.
     * @param {number} i The index to compute
     * @return {Position}
     */
    Lexer.prototype.strpos = function (i) {
        var lines = this._state.source.substring(0, i).split(/\r?\n/);
        if (!Array.isArray(lines))
            lines = [lines];
        var line = lines.length;
        var column = lines[lines.length - 1].length + 1;
        return { line: line, column: column };
    };
    /**
     * Converts the token stream to an array of Tokens
     * @return {Token<T>[]} The array of tokens (not including (EOF))
     */
    Lexer.prototype.toArray = function () {
        var oldState = this._state.copy();
        this._state.position = 0;
        var tkns = [];
        var t;
        while (!(t = this.next()).isEof() // tslint:disable-line no-conditional-assignment
        )
            tkns.push(t);
        this._state = oldState;
        return tkns;
    };
    /**
     * Creates a new token type
     * @param {T} type The token type
     * @param {string|RegExp} pattern The pattern to match
     * @param {?boolean} skip Whether this type of token should be skipped
     * @return {Lexer<T>}
     */
    Lexer.prototype.token = function (type, pattern, skip) {
        this._tokenTypes.token(type, pattern, skip);
        return this;
    };
    /**
     * Creates a keyword
     * @param kwd The keyword to add as a token
     */
    Lexer.prototype.keyword = function (kwd) {
        return this.token(kwd, new RegExp(kwd + "(?=\\W|$)"));
    };
    /**
     * Creates an operator
     * @param op The operator to add as a token
     */
    Lexer.prototype.operator = function (op) {
        var sOp = new String(op).valueOf();
        return this.token(op, sOp);
    };
    return Lexer;
}());
exports.default = Lexer;
//# sourceMappingURL=lexer.js.map